#!/usr/bin/env python3
"""
æµ‹è¯•å•ä¸ªæ–‡ä»¶çš„å¤„ç†åŠŸèƒ½
ç”¨äºéªŒè¯æ˜ å°„å’Œéæ˜ å°„æ¨¡å¼çš„è¾“å‡º
"""

import os
import sys
import pandas as pd
from src.config import BASE_PATH, RESOURCE_DIR
from src.preprocess import process_single_zip

def find_first_zip(year=2019):
    """æ‰¾åˆ°ç¬¬ä¸€ä¸ªå¯ç”¨çš„ ZIP æ–‡ä»¶"""
    for month in range(1, 13):
        for day in range(1, 32):
            zip_name = f"CN-Reanalysis{year}{month:02d}{day:02d}.zip"
            zip_path = os.path.join('./data', str(year), zip_name)
            print(zip_path)
            if os.path.exists(zip_path):
                return zip_path
    return None

def test_single_file():
    """æµ‹è¯•å•ä¸ªæ–‡ä»¶çš„å¤„ç†"""
    print("=== æµ‹è¯•å•ä¸ªæ–‡ä»¶å¤„ç† ===\n")

    # æ‰¾åˆ°ç¬¬ä¸€ä¸ªå¯ç”¨çš„ ZIP æ–‡ä»¶
    zip_path = find_first_zip()
    if not zip_path:
        print("âŒ æœªæ‰¾åˆ°ä»»ä½• ZIP æ–‡ä»¶")
        return

    print(f"ğŸ“ æ‰¾åˆ°æµ‹è¯•æ–‡ä»¶: {zip_path}")

    # æ£€æŸ¥ GeoJSON æ–‡ä»¶
    china_geojson = os.path.join(RESOURCE_DIR, 'ä¸­å›½_å¸‚.pretty.json')
    gadm_geojson = os.path.join(RESOURCE_DIR, 'GADM', 'gadm41_CHN_2.json')

    print(f"ğŸ“ ä¸­å›½å¸‚ GeoJSON: {'âœ… å­˜åœ¨' if os.path.exists(china_geojson) else 'âŒ ä¸å­˜åœ¨'}")
    print(f"ğŸ“ GADM GeoJSON: {'âœ… å­˜åœ¨' if os.path.exists(gadm_geojson) else 'âŒ ä¸å­˜åœ¨'}")

    # æµ‹è¯•1: æœ‰æ˜ å°„çš„å¤„ç†ï¼ˆä½¿ç”¨ä¸­å›½_å¸‚.pretty.jsonï¼‰
    print("\nğŸ”„ æµ‹è¯•1: çœå¸‚æ˜ å°„æ¨¡å¼")
    try:
        result1 = process_single_zip(
            zip_path,
            granularity='city',
            admin_geojson=china_geojson if os.path.exists(china_geojson) else None,
            aggregate_mean=True,
            no_mapping=False
        )
        print(f"âœ… æ˜ å°„æ¨¡å¼æˆåŠŸ: {result1}")

        # æ˜¾ç¤ºç»“æœæ–‡ä»¶çš„æ ·æœ¬
        if os.path.exists(result1):
            try:
                if result1.endswith('.json'):
                    # è¯»å–JSONæ–‡ä»¶
                    import json
                    with open(result1, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                    df1 = pd.DataFrame(data)
                elif result1.endswith('.parquet'):
                    df1 = pd.read_parquet(result1)
                else:
                    df1 = pd.read_csv(result1)

                print(f"ğŸ“Š æ˜ å°„æ¨¡å¼ç»“æœ: {len(df1)} è¡Œ, {len(df1.columns)} åˆ—")
                print("ğŸ“‹ åˆ—å:", list(df1.columns))
                print("ğŸ“‹ å‰5è¡Œæ ·æœ¬:")
                print(df1.head().to_string(index=False))
            except Exception as e:
                print(f"âš ï¸ è¯»å–ç»“æœæ–‡ä»¶å¤±è´¥: {e}")

    except Exception as e:
        print(f"âŒ æ˜ å°„æ¨¡å¼å¤±è´¥: {e}")

    # æµ‹è¯•2: æ— æ˜ å°„çš„å¤„ç†ï¼ˆåªä¿ç•™ç½‘æ ¼æ•°æ®ï¼‰
    print("\nğŸ”„ æµ‹è¯•2: æ— æ˜ å°„ç½‘æ ¼æ¨¡å¼")
    try:
        result2 = process_single_zip(
            zip_path,
            granularity='grid',
            admin_geojson=None,
            aggregate_mean=True,
            no_mapping=True
        )
        print(f"âœ… æ— æ˜ å°„æ¨¡å¼æˆåŠŸ: {result2}")

        # æ˜¾ç¤ºç»“æœæ–‡ä»¶çš„æ ·æœ¬
        if os.path.exists(result2):
            try:
                if result2.endswith('.json'):
                    # è¯»å–JSONæ–‡ä»¶
                    import json
                    with open(result2, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                    df2 = pd.DataFrame(data)
                elif result2.endswith('.parquet'):
                    df2 = pd.read_parquet(result2)
                else:
                    df2 = pd.read_csv(result2)

                print(f"ğŸ“Š æ— æ˜ å°„æ¨¡å¼ç»“æœ: {len(df2)} è¡Œ, {len(df2.columns)} åˆ—")
                print("ğŸ“‹ åˆ—å:", list(df2.columns))
                print("ğŸ“‹ å‰5è¡Œæ ·æœ¬:")
                print(df2.head().to_string(index=False))
            except Exception as e:
                print(f"âš ï¸ è¯»å–ç»“æœæ–‡ä»¶å¤±è´¥: {e}")

    except Exception as e:
        print(f"âŒ æ— æ˜ å°„æ¨¡å¼å¤±è´¥: {e}")

    print("\n=== æµ‹è¯•å®Œæˆ ===")

if __name__ == '__main__':
    # è®¾ç½®è°ƒè¯•æ¨¡å¼å’Œè·³è¿‡ IQRï¼ˆåŠ é€Ÿæµ‹è¯•ï¼‰
    os.environ['PREPROCESS_DEBUG'] = '1'
    os.environ['PREPROCESS_SKIP_IQR'] = '1'

    test_single_file()
